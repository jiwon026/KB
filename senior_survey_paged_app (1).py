# app.py
import os
import numpy as np
import pandas as pd
import streamlit as st
import joblib

# (FAISS ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ sklearnìœ¼ë¡œ ëŒ€ì²´)
USE_FAISS = True
try:
    import faiss  # pip: faiss-cpu
except Exception as e:
    USE_FAISS = False
    from sklearn.neighbors import NearestNeighbors

# =================================
# ê¸°ë³¸ ì„¤ì •
# =================================
st.set_page_config(page_title="ì‹œë‹ˆì–´ ê¸ˆìœµ ì„¤ë¬¸ & ì¶”ì²œ", page_icon="ğŸ’¸", layout="centered")

BASE_DIR = os.path.dirname(os.path.abspath(__file__)) if "__file__" in globals() else os.getcwd()
MODELS_DIR = BASE_DIR
DEPOSIT_CSV = "ê¸ˆìœµìƒí’ˆ_3ê°œ_í†µí•©ë³¸.csv"  # ì˜ˆÂ·ì ê¸ˆ CSV
FUND_CSV    = "í€ë“œ_ë³‘í•©ë³¸.csv"          # í€ë“œ CSV

# ì˜ˆì¸¡â†’ì„¤ë¬¸ í”„ë¦¬í•„ ê°’ì„ ì‚¬ìš©ìê°€ ìˆ˜ì • ëª» í•˜ê²Œ ì ê¸€ì§€ ì—¬ë¶€
LOCK_INFERRED_FIELDS = False  # Trueë©´ ìë™ ì±„ìš´ ì†Œë“/ì—°ê¸ˆ ì¹¸ ë¹„í™œì„±í™”

# =================================
# ê³µí†µ ìœ í‹¸ (ì¸ë±ìŠ¤ ë¹Œë“œ/ê²€ìƒ‰)
# =================================
def build_index(X: np.ndarray):
    X = X.astype("float32")
    if USE_FAISS:
        index = faiss.IndexFlatL2(X.shape[1])
        index.add(X)
        return index
    nn = NearestNeighbors(metric="euclidean")
    nn.fit(X)
    return nn

def index_search(index, q: np.ndarray, k: int):
    q = q.astype("float32")
    if USE_FAISS:
        return index.search(q, k)
    D, I = index.kneighbors(q, n_neighbors=k, return_distance=True)
    return D, I

# =================================
# ëª¨ë¸/ë°ì´í„° ë¡œë”© (ìºì‹œ)
# =================================
@st.cache_resource
def load_models():
    """ëª¨ë¸ íŒŒì¼ì´ ì—†ì–´ë„ ì•±ì´ ì£½ì§€ ì•Šê²Œ ì•ˆì „ ë¡œë”©"""
    def safe_load(name):
        path = os.path.join(MODELS_DIR, name)
        if not os.path.exists(path):
            st.info(f"ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {name} â†’ ê±´ë„ˆëœ€")
            return None
        try:
            return joblib.load(path)
        except Exception as e:
            st.warning(f"{name} ë¡œë“œ ì‹¤íŒ¨: {e.__class__.__name__}: {e}")
            return None

    survey_model   = safe_load("tabnet_model.pkl")
    survey_encoder = safe_load("label_encoder.pkl")
    reg_model      = safe_load("reg_model.pkl")
    type_model     = safe_load("type_model.pkl")
    return survey_model, survey_encoder, reg_model, type_model

@st.cache_data
def load_deposit_csv():
    path = os.path.join(BASE_DIR, DEPOSIT_CSV)
    if not os.path.exists(path):
        raise FileNotFoundError(f"ì˜ˆÂ·ì ê¸ˆ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}")
    for enc in ("utf-8-sig", "cp949"):
        try: return pd.read_csv(path, encoding=enc)
        except UnicodeDecodeError: pass
    return pd.read_csv(path)

@st.cache_data
def load_fund_csv():
    path = os.path.join(BASE_DIR, FUND_CSV)
    if not os.path.exists(path):
        raise FileNotFoundError(f"í€ë“œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}")
    for enc in ("utf-8-sig", "cp949"):
        try: return pd.read_csv(path, encoding=enc)
        except UnicodeDecodeError: pass
    return pd.read_csv(path)

survey_model, survey_encoder, reg_model, type_model = load_models()

# =================================
# ì „ì²˜ë¦¬ & ì¶”ì²œ ìœ í‹¸
# =================================
def preprocess_products(df: pd.DataFrame, group_name: str = "") -> pd.DataFrame:
    """CSV â†’ ê³µí†µ ì „ì²˜ë¦¬. group_name='ì˜ˆÂ·ì ê¸ˆ' ë˜ëŠ” 'í€ë“œ' ë¼ë²¨."""
    np.random.seed(42)
    df = df.copy()
    df.columns = df.columns.str.strip()

    # ìƒí’ˆëª…
    if 'ìƒí’ˆëª…' in df.columns:
        names = df['ìƒí’ˆëª…'].fillna('ë¬´ëª…ìƒí’ˆ').astype(str)
    elif 'í€ë“œëª…' in df.columns:
        names = df['í€ë“œëª…'].fillna('ë¬´ëª…ìƒí’ˆ').astype(str)
    elif 'ì¶œì²˜íŒŒì¼ëª…' in df.columns:
        names = df['ì¶œì²˜íŒŒì¼ëª…'].apply(lambda x: str(x).split('.')[0] if pd.notnull(x) else 'ë¬´ëª…ìƒí’ˆ')
    else:
        names = [f"ë¬´ëª…ìƒí’ˆ_{i}" for i in range(len(df))]

    # ìµœì†Œ íˆ¬ìê¸ˆì•¡
    if 'ìµœê³ í•œë„' in df.columns:
        min_invest = pd.to_numeric(df['ìµœê³ í•œë„'], errors='coerce').fillna(0)
        zero_mask = (min_invest == 0)
        if zero_mask.any():
            min_invest.loc[zero_mask] = np.random.randint(100, 1000, zero_mask.sum())
    elif 'ìµœì†Œê°€ì…ê¸ˆì•¡' in df.columns:
        min_invest = pd.to_numeric(df['ìµœì†Œê°€ì…ê¸ˆì•¡'], errors='coerce')
        miss = min_invest.isna()
        if miss.any():
            min_invest.loc[miss] = np.random.randint(100, 1000, miss.sum())
    else:
        min_invest = pd.Series(np.random.randint(100, 1000, len(df)), index=df.index)

    # ìˆ˜ìµë¥ (%) â†’ ì†Œìˆ˜
    cand_cols = [c for c in df.columns if any(k in c for k in ["ê¸°ë³¸ê¸ˆë¦¬", "ì´ììœ¨", "ì„¸ì „", "%", "ìˆ˜ìµë¥ ", "ìˆ˜ìµ"])]
    rate_col = cand_cols[0] if cand_cols else None
    if rate_col:
        raw = (df[rate_col].astype(str)
                         .str.replace(",", "", regex=False)
                         .str.extract(r"([\d\.]+)")[0])
        est_return = pd.to_numeric(raw, errors="coerce")
        rand_series = pd.Series(np.random.uniform(1.0, 8.0, len(df)), index=df.index)
        est_return = (est_return.fillna(rand_series) / 100.0).astype(float).round(4)
    else:
        low, high = (0.01, 0.08) if group_name != "í€ë“œ" else (0.03, 0.15)
        est_return = pd.Series(np.round(np.random.uniform(low, high, len(df)), 4), index=df.index)

    # ë¦¬ìŠ¤í¬
    if 'ìœ„í—˜ë“±ê¸‰' in df.columns:
        raw_risk = df['ìœ„í—˜ë“±ê¸‰'].astype(str)
        risk = raw_risk.apply(lambda x: 'ë†’ìŒ' if ('5' in x or '4' in x) else ('ì¤‘ê°„' if '3' in x else 'ë‚®ìŒ'))
    else:
        if group_name == "í€ë“œ":
            risk = pd.Series(np.random.choice(['ë‚®ìŒ','ì¤‘ê°„','ë†’ìŒ'], len(df), p=[0.2,0.4,0.4]), index=df.index)
        else:
            risk = pd.Series(np.random.choice(['ë‚®ìŒ','ì¤‘ê°„','ë†’ìŒ'], len(df), p=[0.6,0.3,0.1]), index=df.index)

    # ê¶Œì¥ê¸°ê°„/íˆ¬ìì„±í–¥(í•„í„°ìš©)
    duration = pd.Series(np.random.choice([6, 12, 24, 36], len(df)), index=df.index)
    profile  = pd.Series(np.random.choice(['ì•ˆì •í˜•','ìœ„í—˜ì¤‘ë¦½í˜•','ê³µê²©í˜•'], len(df)), index=df.index)

    out = pd.DataFrame({
        'êµ¬ë¶„': group_name if group_name else 'ê¸°íƒ€',
        'ìƒí’ˆëª…': names,
        'ìµœì†Œíˆ¬ìê¸ˆì•¡': min_invest.astype(int),
        'ì˜ˆìƒìˆ˜ìµë¥ ': est_return,
        'ë¦¬ìŠ¤í¬': risk,
        'ê¶Œì¥íˆ¬ìê¸°ê°„': duration,
        'íˆ¬ìì„±í–¥': profile
    })
    return out[out['ìƒí’ˆëª…'] != 'ë¬´ëª…ìƒí’ˆ'].drop_duplicates(subset=['ìƒí’ˆëª…']).reset_index(drop=True)

def rule_based_filter(df: pd.DataFrame, user: dict) -> pd.DataFrame:
    risk_pref_map = {
        'ì•ˆì •í˜•': ['ë‚®ìŒ','ì¤‘ê°„'],
        'ìœ„í—˜ì¤‘ë¦½í˜•': ['ì¤‘ê°„','ë‚®ìŒ','ë†’ìŒ'],
        'ê³µê²©í˜•': ['ë†’ìŒ','ì¤‘ê°„']
    }
    allowed = risk_pref_map.get(user['íˆ¬ìì„±í–¥'], ['ë‚®ìŒ','ì¤‘ê°„','ë†’ìŒ'])
    f = df[
        (df['ìµœì†Œíˆ¬ìê¸ˆì•¡'] <= user['íˆ¬ìê¸ˆì•¡']) &
        (df['ê¶Œì¥íˆ¬ìê¸°ê°„'] <= user['íˆ¬ìê¸°ê°„']) &
        (df['ë¦¬ìŠ¤í¬'].isin(allowed))
    ]
    return f.sort_values('ì˜ˆìƒìˆ˜ìµë¥ ', ascending=False).head(500).reset_index(drop=True)

def _get_feature_vector(df: pd.DataFrame) -> np.ndarray:
    return np.vstack([
        df['ìµœì†Œíˆ¬ìê¸ˆì•¡'].astype(float) / 1000.0,
        df['ì˜ˆìƒìˆ˜ìµë¥ '].astype(float) * 100.0,
        df['ê¶Œì¥íˆ¬ìê¸°ê°„'].astype(float) / 12.0
    ]).T.astype('float32')

def _get_user_vector(user: dict) -> np.ndarray:
    return np.array([
        user['íˆ¬ìê¸ˆì•¡'] / 1000.0,
        user['ëª©í‘œì›”ì´ì'],
        user['íˆ¬ìê¸°ê°„'] / 12.0
    ], dtype='float32').reshape(1, -1)

def _add_explain(df: pd.DataFrame, user: dict) -> pd.DataFrame:
    out = df.copy()
    out['ì›”ì˜ˆìƒìˆ˜ìµê¸ˆ(ë§Œì›)'] = (out['ì˜ˆìƒìˆ˜ìµë¥ '].astype(float) * user['íˆ¬ìê¸ˆì•¡'] / 12.0).round(1)
    out['íˆ¬ìê¸°ê°„(ê°œì›”)'] = out['ê¶Œì¥íˆ¬ìê¸°ê°„'].astype(int)
    out['ì˜ˆìƒìˆ˜ìµë¥ (ì—°)'] = (out['ì˜ˆìƒìˆ˜ìµë¥ '] * 100).round(2).astype(str) + '%'
    cols = ['êµ¬ë¶„','ìƒí’ˆëª…','ì›”ì˜ˆìƒìˆ˜ìµê¸ˆ(ë§Œì›)','ì˜ˆìƒìˆ˜ìµë¥ (ì—°)','ë¦¬ìŠ¤í¬','íˆ¬ìê¸°ê°„(ê°œì›”)']
    return out[cols]

def recommend_fallback_split(user: dict) -> pd.DataFrame:
    """CSV ë‘ ê°œ(ì˜ˆÂ·ì ê¸ˆ/í€ë“œ)ë¡œ ì¦‰ì‹œ êµ¬ì¶•: ì˜ˆÂ·ì ê¸ˆ 2 + í€ë“œ 1"""
    dep_raw = load_deposit_csv()
    fun_raw = load_fund_csv()

    dep = preprocess_products(dep_raw, "ì˜ˆÂ·ì ê¸ˆ")
    fun = preprocess_products(fun_raw, "í€ë“œ")

    dep_f = rule_based_filter(dep, user)
    fun_f = rule_based_filter(fun, user)

    if dep_f.empty and fun_f.empty:
        return pd.DataFrame({'ë©”ì‹œì§€': ['ì¡°ê±´ì— ë§ëŠ” ìƒí’ˆì´ ì—†ì–´ìš” ğŸ˜¢']})

    # ì˜ˆÂ·ì ê¸ˆ 2
    if not dep_f.empty:
        Xd = _get_feature_vector(dep_f)
        idxd = build_index(Xd)
        _, idd = index_search(idxd, _get_user_vector(user), min(2, len(dep_f)))
        rec_dep = dep_f.iloc[idd[0]].copy().head(2)
    else:
        rec_dep = pd.DataFrame(columns=dep_f.columns)

    # í€ë“œ 1
    if not fun_f.empty:
        Xf = _get_feature_vector(fun_f)
        idxf = build_index(Xf)
        _, idf = index_search(idxf, _get_user_vector(user), min(1, len(fun_f)))
        rec_fun = fun_f.iloc[idf[0]].copy().head(1)
    else:
        rec_fun = pd.DataFrame(columns=fun_f.columns)

    out = pd.concat([rec_dep, rec_fun], ignore_index=True)
    out = out.drop_duplicates(subset=['ìƒí’ˆëª…']).reset_index(drop=True)
    return _add_explain(out, user)

# =================================
# ê²°ê³¼ í™”ë©´ (ìŠ¤ì¼€ì¹˜ ìŠ¤íƒ€ì¼)
# =================================
TYPE_DESCRIPTIONS = {
    "ì•ˆì •í˜•": "ìì‚°/ì—°ê¸ˆ ë¹„ìœ¨ì´ ì•ˆì •ì ì´ê³  ì›ê¸ˆ ë³´ì „ì„ ì„ í˜¸í•´ìš”. ì˜ˆÂ·ì ê¸ˆê³¼ ì´ˆì €ìœ„í—˜ ìƒí’ˆ ìœ„ì£¼ê°€ ì¢‹ì•„ìš”.",
    "ì•ˆì •ì¶”êµ¬í˜•": "ìˆ˜ìµê³¼ ì•ˆì •ì˜ ê· í˜•ì„ ì¤‘ì‹œí•´ìš”. ì˜ˆÂ·ì ê¸ˆ + ì´ˆì €ìœ„í—˜ í€ë“œë¥¼ ì†Œí­ ì„ëŠ” êµ¬ì„±ì´ ì í•©í•´ìš”.",
    "ìœ„í—˜ì¤‘ë¦½í˜•": "ìœ„í—˜/ìˆ˜ìµì„ ê· í˜• ìˆê²Œ ë°›ì•„ë“¤ì—¬ìš”. ì±„ê¶Œí˜•Â·í˜¼í•©í˜•ê³¼ ì ê¸ˆì„ í˜¼í•©í•˜ë©´ ì¢‹ì•„ìš”.",
    "ì ê·¹íˆ¬ìí˜•": "ìˆ˜ìµì„ ìœ„í•´ ë³€ë™ì„±ì„ ì¼ì • ìˆ˜ì¤€ í—ˆìš©í•´ìš”. í˜¼í•©í˜•/ì£¼ì‹í˜• ë¹„ì¤‘ì„ ì¡°ê¸ˆ ë” ë†’ì—¬ìš”.",
    "ê³µê²©íˆ¬ìí˜•": "ë†’ì€ ìˆ˜ìµì„ ìœ„í•´ ë³€ë™ì„± ê°ë‚´ë„ê°€ ë†’ì•„ìš”. ì£¼ì‹í˜•Â·í…Œë§ˆí˜• ë“± ì„±ì¥ì§€í–¥ ìƒí’ˆì„ ê³ ë ¤í•´ìš”.",
}
DEFAULT_TYPE = "ì•ˆì •í˜•"

def render_final_screen(fin_type: str, rec_df: pd.DataFrame):
    fin_type = fin_type if fin_type in TYPE_DESCRIPTIONS else DEFAULT_TYPE
    desc = TYPE_DESCRIPTIONS[fin_type]

    st.markdown("""
    <style>
      .hero { font-size: 38px; font-weight: 800; margin: 4px 0 8px 0; }
      .desc { font-size: 16px; opacity: 0.9; margin-bottom: 18px; }
      .cards { display: grid; grid-template-columns: repeat(3, 1fr); gap: 14px; }
      .card {
        border: 2px solid #eaeaea; border-radius: 18px; padding: 16px 14px;
        box-shadow: 0 4px 14px rgba(0,0,0,0.06); background: #fff;
      }
      .badge {
        display:inline-flex; align-items:center; justify-content:center;
        width:28px; height:28px; border-radius:50%; color:#fff; font-weight:700;
        margin-right:8px;
      }
      .b1{ background:#ff5a5a; } .b2{ background:#7c4dff; } .b3{ background:#10b981; }
      .pname{ font-size:17px; font-weight:700; margin:6px 0 10px 0; }
      .meta{ font-size:14px; line-height:1.5; }
      .k { font-weight:700; }
    </style>
    """, unsafe_allow_html=True)

    st.markdown(f'<div class="hero">{fin_type}</div>', unsafe_allow_html=True)
    st.markdown(f'<div class="desc">â€¢ {desc}</div>', unsafe_allow_html=True)

    colors = ["b1", "b2", "b3"]
    items = rec_df.head(3).to_dict(orient="records")

    cards = []
    for i, r in enumerate(items, start=1):
        cname = colors[i-1 if i-1 < len(colors) else -1]
        name = str(r.get("ìƒí’ˆëª…", "-"))
        mret = r.get("ì›”ì˜ˆìƒìˆ˜ìµê¸ˆ(ë§Œì›)", "-")
        risk = r.get("ë¦¬ìŠ¤í¬", "-")
        card_html = (
            f'<div class="card">'
            f'<div><span class="badge {cname}">{i}</span><span class="pname">{name}</span></div>'
            f'<div class="meta"><span class="k">ì›” ì˜ˆìƒìˆ˜ìµ</span> {mret}ë§Œì›</div>'
            f'<div class="meta"><span class="k">ë¦¬ìŠ¤í¬</span> {risk}</div>'
            f'</div>'
        )
        cards.append(card_html)

    cards_html = '<div class="cards">' + ''.join(cards) + '</div>'
    st.markdown(cards_html, unsafe_allow_html=True)

# =================================
# UI íë¦„
# =================================
st.title("ğŸ’¬ ì‹œë‹ˆì–´ ê¸ˆìœµ ì„¤ë¬¸ & ì¶”ì²œ ì‹œìŠ¤í…œ")

ss = st.session_state
ss.setdefault("flow", "choose")      # choose â†’ predict â†’ survey â†’ recommend
ss.setdefault("pred_amount", None)
ss.setdefault("answers", {})
ss.setdefault("prefill_survey", {})  # ì˜ˆì¸¡â†’ì„¤ë¬¸ í”„ë¦¬í•„
ss.setdefault("pred_label", None)    # ì˜ˆì¸¡ëœ ê¸ˆìœµ ìœ í˜•

# ê³µí†µ ì„¤ë¬¸ ë¬¸í•­
QUESTIONS = [
    ("ë‚˜ì´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", "number", "age"),
    ("ì„±ë³„ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", "select", "gender", ["ë‚¨ì„±", "ì—¬ì„±"]),
    ("ê°€êµ¬ì› ìˆ˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", "number", "family_size"),
    ("í”¼ë¶€ì–‘ìê°€ ìˆë‚˜ìš”?", "select", "dependents", ["ì˜ˆ", "ì•„ë‹ˆì˜¤"]),
    ("í˜„ì¬ ë³´ìœ í•œ ê¸ˆìœµìì‚°(ë§Œì›)ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", "number", "assets"),
    ("ì›” ìˆ˜ë ¹í•˜ëŠ” ì—°ê¸ˆ ê¸ˆì•¡(ë§Œì›)ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", "number", "pension"),
    ("ì›” í‰ê·  ì§€ì¶œë¹„(ë§Œì›)ì€ ì–¼ë§ˆì¸ê°€ìš”?", "number", "living_cost"),
    ("ì›” í‰ê·  ì†Œë“ì€ ì–¼ë§ˆì¸ê°€ìš”?", "number", "income"),
    ("íˆ¬ì ì„±í–¥ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", "select", "risk",
        ["ì•ˆì •í˜•", "ì•ˆì •ì¶”êµ¬í˜•", "ìœ„í—˜ì¤‘ë¦½í˜•", "ì ê·¹íˆ¬ìí˜•", "ê³µê²©íˆ¬ìí˜•"]),
]

def render_survey(defaults: dict | None = None, lock_inferred: bool = False):
    """ì„¤ë¬¸ ë Œë”ëŸ¬: defaultsë¡œ ê¸°ë³¸ê°’ ì£¼ì…, lock_inferred=Trueë©´ í•´ë‹¹ ì¹¸ ë¹„í™œì„±í™”"""
    st.subheader("ğŸ“ ì„¤ë¬¸")
    answers = {}
    defaults = defaults or {}

    # ê¸°ë³¸ê°’ì„ ì„¸ì…˜í‚¤ì— ì‹¬ì–´ì¤Œ(ìµœì´ˆ 1íšŒ)
    def _seed_default(key, value):
        skey = f"q_{key}"
        if (skey not in st.session_state) and (value is not None):
            st.session_state[skey] = value

    _seed_default("income",  defaults.get("income"))
    _seed_default("pension", defaults.get("pension"))

    for q in QUESTIONS:
        title, kind, key = q[0], q[1], q[2]
        disabled = lock_inferred and (key in defaults)

        if kind == "number":
            answers[key] = st.number_input(title, min_value=0, step=1, key=f"q_{key}", disabled=disabled)
        elif kind == "select":
            answers[key] = st.selectbox(title, q[3], key=f"q_{key}", disabled=disabled)
    return answers

def map_survey_to_model_input(r):
    gender = 0 if r["gender"] == "ë‚¨ì„±" else 1
    dependents = 1 if r["dependents"] == "ì˜ˆ" else 0
    risk_map = {"ì•ˆì •í˜•": 0, "ì•ˆì •ì¶”êµ¬í˜•": 1, "ìœ„í—˜ì¤‘ë¦½í˜•": 2, "ì ê·¹íˆ¬ìí˜•": 3, "ê³µê²©íˆ¬ìí˜•": 4}
    risk = risk_map[r["risk"]]
    arr = np.array([[
        float(r["age"]), gender, float(r["family_size"]), dependents,
        float(r["assets"]), float(r["pension"]), float(r["living_cost"]),
        float(r["income"]), risk
    ]])
    return arr

# 1) ì—°ê¸ˆ ìˆ˜ë ¹ ì—¬ë¶€
if ss.flow == "choose":
    st.markdown("### 1ï¸âƒ£ í˜„ì¬ ì—°ê¸ˆì„ ë°›ê³  ê³„ì‹ ê°€ìš”?")
    choice = st.radio("ì—°ê¸ˆ ìˆ˜ë ¹ ì—¬ë¶€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.", ["ì„ íƒí•˜ì„¸ìš”", "ì˜ˆ(ìˆ˜ë ¹ ì¤‘)", "ì•„ë‹ˆì˜¤(ë¯¸ìˆ˜ë ¹)"], index=0)
    if choice == "ì˜ˆ(ìˆ˜ë ¹ ì¤‘)":
        ss.flow = "survey"
    elif choice == "ì•„ë‹ˆì˜¤(ë¯¸ìˆ˜ë ¹)":
        ss.flow = "predict"

# 2-1) ë¯¸ìˆ˜ë ¹ì â†’ ì—°ê¸ˆ ê³„ì‚°ê¸°
if ss.flow == "predict":
    st.subheader("ğŸ“ˆ ì—°ê¸ˆ ê³„ì‚°ê¸°")
    income = st.number_input("í‰ê·  ì›”ì†Œë“(ë§Œì›)", min_value=0, step=1, key="pred_income")
    years  = st.number_input("êµ­ë¯¼ì—°ê¸ˆ ê°€ì…ê¸°ê°„(ë…„)", min_value=0, max_value=50, step=1, key="pred_years")

    if st.button("ì—°ê¸ˆ ì˜ˆì¸¡í•˜ê¸°"):
        if reg_model is None:
            st.info("ì—°ê¸ˆ ì˜ˆì¸¡ ëª¨ë¸ì´ ì—†ì–´ ê³„ì‚°ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            ss.prefill_survey = {"income": income, "pension": 0}
        else:
            try:
                X = pd.DataFrame([{"í‰ê· ì›”ì†Œë“(ë§Œì›)": income, "ê°€ì…ê¸°ê°„(ë…„)": years}])
                amount = round(float(reg_model.predict(X)[0]), 1)
                ss.pred_amount = amount
                # ì„¤ë¬¸ í”„ë¦¬í•„ ì €ì¥(ìë™ ì—°ê²°)
                ss.prefill_survey = {"income": income, "pension": amount}

                def classify_pension_type(a):
                    if a >= 90: return "ì™„ì „ë…¸ë ¹ì—°ê¸ˆ"
                    if a >= 60: return "ì¡°ê¸°ë…¸ë ¹ì—°ê¸ˆ"
                    if a >= 30: return "ê°ì•¡ë…¸ë ¹ì—°ê¸ˆ"
                    return "íŠ¹ë¡€ë…¸ë ¹ì—°ê¸ˆ"

                ptype = classify_pension_type(amount)
                explains = {
                    "ì¡°ê¸°ë…¸ë ¹ì—°ê¸ˆ": "â€» ë§Œ 60ì„¸ë¶€í„° ìˆ˜ë ¹ ê°€ëŠ¥í•˜ë‚˜ ìµœëŒ€ 30% ê°ì•¡ë  ìˆ˜ ìˆì–´ìš”.",
                    "ì™„ì „ë…¸ë ¹ì—°ê¸ˆ": "â€» ë§Œ 65ì„¸ë¶€í„° ê°ì•¡ ì—†ì´ ì •ì•¡ ìˆ˜ë ¹ì´ ê°€ëŠ¥í•´ìš”.",
                    "ê°ì•¡ë…¸ë ¹ì—°ê¸ˆ": "â€» ì¼ì • ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ëª»í•  ê²½ìš° ê°ì•¡ë˜ì–´ ìˆ˜ë ¹ë©ë‹ˆë‹¤.",
                    "íŠ¹ë¡€ë…¸ë ¹ì—°ê¸ˆ": "â€» ê°€ì…ê¸°ê°„ì´ ì§§ë”ë¼ë„ ì¼ì • ê¸°ì¤€ ì¶©ì¡± ì‹œ ìˆ˜ë ¹ ê°€ëŠ¥."
                }
                st.success(f"ğŸ’° ì˜ˆì¸¡ ì—°ê¸ˆ ìˆ˜ë ¹ì•¡: **{amount}ë§Œì›/ì›”**")
                st.markdown(f"ğŸ“‚ ì˜ˆì¸¡ ì—°ê¸ˆ ìœ í˜•: **{ptype}**")
                st.info(explains[ptype])
            except Exception as e:
                st.exception(e)

        ss.flow = "survey"

# 2) ìˆ˜ë ¹ì/ë¯¸ìˆ˜ë ¹ì ê³µí†µ â†’ ì„¤ë¬¸ â†’ ìœ í˜• ë¶„ë¥˜
if ss.flow == "survey":
    answers = render_survey(defaults=ss.get("prefill_survey", {}), lock_inferred=LOCK_INFERRED_FIELDS)
    if st.button("ìœ í˜• ë¶„ë¥˜í•˜ê¸°"):
        if (survey_model is None) or (survey_encoder is None):
            st.info("ë¶„ë¥˜ ëª¨ë¸ì´ ì—†ì–´ ì„¤ë¬¸ ê²°ê³¼ë§Œ ì €ì¥í•˜ê³  ì¶”ì²œ ë‹¨ê³„ë¡œ ë„˜ì–´ê°ˆê²Œìš”.")
            ss.pred_label = answers.get("risk") or "ì•ˆì •í˜•"
            ss.answers = answers
            ss.flow = "recommend"
        else:
            try:
                arr = map_survey_to_model_input(answers)
                pred = survey_model.predict(arr)
                label = survey_encoder.inverse_transform(pred)[0]
                ss.pred_label = label  # ğŸ”¸ ì˜ˆì¸¡ëœ ê¸ˆìœµ ìœ í˜• ì €ì¥

                proba_method = getattr(survey_model, "predict_proba", None)
                if callable(proba_method):
                    proba = proba_method(arr)
                    proba_df = pd.DataFrame(proba, columns=survey_encoder.classes_)
                    st.bar_chart(proba_df.T)
                    st.success(f"ğŸ§¾ ì˜ˆì¸¡ëœ ê¸ˆìœµ ìœ í˜•: **{label}**")
                else:
                    st.success(f"ğŸ§¾ ì˜ˆì¸¡ëœ ê¸ˆìœµ ìœ í˜•: **{label}**")
            except Exception as e:
                st.exception(e)
            ss.answers = answers
            ss.flow = "recommend"

# 3) ì¶”ì²œ: ì„¤ë¬¸ + íˆ¬ìì¡°ê±´ ì…ë ¥ â†’ ì¶”ì²œ (ì˜ˆÂ·ì ê¸ˆ 2 + í€ë“œ 1)
if ss.flow == "recommend":
    st.markdown("---")
    st.subheader("ğŸ§² ê¸ˆìœµìƒí’ˆ ì¶”ì²œ")

    invest_amount  = st.number_input("íˆ¬ìê¸ˆì•¡(ë§Œì›)", min_value=10, step=10, value=500)
    invest_period  = st.selectbox("íˆ¬ìê¸°ê°„(ê°œì›”)", [6, 12, 24, 36], index=1)
    risk_choice    = st.selectbox("ë¦¬ìŠ¤í¬ í—ˆìš©ë„", ["ì•ˆì •í˜•", "ìœ„í—˜ì¤‘ë¦½í˜•", "ê³µê²©í˜•"], index=1)
    target_monthly = st.number_input("ëª©í‘œ ì›”ì´ì(ë§Œì›)", min_value=1, step=1, value=10)

    if st.button("ì¶”ì²œ ë³´ê¸°"):
        user_pref = {
            'íˆ¬ìê¸ˆì•¡': invest_amount,
            'íˆ¬ìê¸°ê°„': invest_period,
            'íˆ¬ìì„±í–¥': risk_choice,
            'ëª©í‘œì›”ì´ì': target_monthly
        }
        rec_df = recommend_fallback_split(user_pref)  # ì €ì¥ ì¸ë±ìŠ¤ ì—†ì´ë„ ë™ì‘
        if "ë©”ì‹œì§€" in rec_df.columns:
            st.warning(rec_df.iloc[0, 0])
        else:
            # ìŠ¤ì¼€ì¹˜ ìŠ¤íƒ€ì¼ ê²°ê³¼ í™”ë©´ ë Œë”
            fin_type = st.session_state.get("pred_label") or risk_choice or "ì•ˆì •í˜•"
            render_final_screen(fin_type, rec_df)

            # CSV ë‹¤ìš´ë¡œë“œ
            csv_bytes = rec_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ì¶”ì²œ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", csv_bytes, "recommendations.csv", "text/csv")

    if st.button("ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        for k in ["flow", "pred_amount", "answers", "prefill_survey", "pred_label"]:
            if k in st.session_state: del st.session_state[k]
        st.rerun()
