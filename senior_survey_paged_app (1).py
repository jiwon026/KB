# app.py
import os
import re
import numpy as np
import pandas as pd
import streamlit as st
import joblib
import faiss

# =================================
# ê¸°ë³¸ ì„¤ì •
# =================================
st.set_page_config(page_title="ì‹œë‹ˆì–´ ê¸ˆìœµ ì„¤ë¬¸ & ì¶”ì²œ", page_icon="ğŸ’¸", layout="centered")

# ì‹¤í–‰ íŒŒì¼ ê¸°ì¤€ ê²½ë¡œ
BASE_DIR = os.path.dirname(os.path.abspath(__file__)) if "__file__" in globals() else os.getcwd()
MODELS_DIR = BASE_DIR
DEPOSIT_CSV = "ê¸ˆìœµìƒí’ˆ_3ê°œ_í†µí•©ë³¸.csv"  # ì˜ˆÂ·ì ê¸ˆ í†µí•© CSV
FUND_CSV    = "í€ë“œ_ë³‘í•©ë³¸.csv"          # í€ë“œ CSV

# =================================
# ëª¨ë¸/ë°ì´í„° ë¡œë”© (ìºì‹œ)
# =================================
@st.cache_resource
def load_models():
    survey_model   = joblib.load(os.path.join(MODELS_DIR, "tabnet_model.pkl"))
    survey_encoder = joblib.load(os.path.join(MODELS_DIR, "label_encoder.pkl"))
    reg_model      = joblib.load(os.path.join(MODELS_DIR, "reg_model.pkl"))
    type_model     = joblib.load(os.path.join(MODELS_DIR, "type_model.pkl"))
    return survey_model, survey_encoder, reg_model, type_model

@st.cache_resource
def load_saved_reco_assets():
    """ì €ì¥ëœ ì¶”ì²œ ìì‚°(FAISS ì¸ë±ìŠ¤ + ë©”íƒ€ë°ì´í„°) ë¡œë”©"""
    assets = {
        "deposit_index": None, "deposit_meta": None,
        "fund_index": None,    "fund_meta": None
    }
    dep_idx_path  = os.path.join(MODELS_DIR, "deposit_index.faiss")
    dep_meta_path = os.path.join(MODELS_DIR, "deposit_metadata.parquet")
    fund_idx_path  = os.path.join(MODELS_DIR, "fund_index.faiss")
    fund_meta_path = os.path.join(MODELS_DIR, "fund_metadata.parquet")

    if os.path.exists(dep_idx_path) and os.path.exists(dep_meta_path):
        assets["deposit_index"] = faiss.read_index(dep_idx_path)
        assets["deposit_meta"]  = pd.read_parquet(dep_meta_path)
    if os.path.exists(fund_idx_path) and os.path.exists(fund_meta_path):
        assets["fund_index"] = faiss.read_index(fund_idx_path)
        assets["fund_meta"]  = pd.read_parquet(fund_meta_path)
    return assets

@st.cache_data
def load_deposit_csv():
    path = os.path.join(BASE_DIR, DEPOSIT_CSV)
    if not os.path.exists(path):
        raise FileNotFoundError(f"ì˜ˆÂ·ì ê¸ˆ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}")
    for enc in ["utf-8-sig", "cp949"]:
        try:
            return pd.read_csv(path, encoding=enc)
        except UnicodeDecodeError:
            continue
    # ìµœí›„ fallback
    return pd.read_csv(path)

@st.cache_data
def load_fund_csv():
    path = os.path.join(BASE_DIR, FUND_CSV)
    if not os.path.exists(path):
        raise FileNotFoundError(f"í€ë“œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}")
    for enc in ["utf-8-sig", "cp949"]:
        try:
            return pd.read_csv(path, encoding=enc)
        except UnicodeDecodeError:
            continue
    return pd.read_csv(path)

survey_model, survey_encoder, reg_model, type_model = load_models()
saved_assets = load_saved_reco_assets()

# =================================
# ì „ì²˜ë¦¬ ë° ì¶”ì²œ ìœ í‹¸
# =================================
def preprocess_products(df: pd.DataFrame, group_name: str = "") -> pd.DataFrame:
    """CSV â†’ ê³µí†µ ì „ì²˜ë¦¬. group_nameìœ¼ë¡œ 'ì˜ˆÂ·ì ê¸ˆ'/'í€ë“œ' ë¼ë²¨ ë¶€ì—¬ ê°€ëŠ¥."""
    np.random.seed(42)
    df = df.copy()
    df.columns = df.columns.str.strip()

    # ìƒí’ˆëª…
    if 'ìƒí’ˆëª…' in df.columns:
        names = df['ìƒí’ˆëª…'].fillna('ë¬´ëª…ìƒí’ˆ').astype(str)
    elif 'í€ë“œëª…' in df.columns:
        names = df['í€ë“œëª…'].fillna('ë¬´ëª…ìƒí’ˆ').astype(str)
    elif 'ì¶œì²˜íŒŒì¼ëª…' in df.columns:
        names = df['ì¶œì²˜íŒŒì¼ëª…'].apply(lambda x: str(x).split('.')[0] if pd.notnull(x) else 'ë¬´ëª…ìƒí’ˆ')
    else:
        names = [f"ë¬´ëª…ìƒí’ˆ_{i}" for i in range(len(df))]

    # ìµœì†Œ íˆ¬ìê¸ˆì•¡
    if 'ìµœê³ í•œë„' in df.columns:
        min_invest = pd.to_numeric(df['ìµœê³ í•œë„'], errors='coerce').fillna(0)
        zero_mask = (min_invest == 0)
        if zero_mask.any():
            min_invest.loc[zero_mask] = np.random.randint(100, 1000, zero_mask.sum())
    elif 'ìµœì†Œê°€ì…ê¸ˆì•¡' in df.columns:
        min_invest = pd.to_numeric(df['ìµœì†Œê°€ì…ê¸ˆì•¡'], errors='coerce')
        miss = min_invest.isna()
        if miss.any():
            min_invest.loc[miss] = np.random.randint(100, 1000, miss.sum())
    else:
        min_invest = pd.Series(np.random.randint(100, 1000, len(df)), index=df.index)

    # ìˆ˜ìµë¥ (%) â†’ ì†Œìˆ˜
    cand_cols = [c for c in df.columns if any(k in c for k in ["ê¸°ë³¸ê¸ˆë¦¬", "ì´ììœ¨", "ì„¸ì „", "%", "ìˆ˜ìµë¥ ", "ìˆ˜ìµ"])]
    rate_col = cand_cols[0] if cand_cols else None
    if rate_col:
        raw = (df[rate_col].astype(str)
                         .str.replace(",", "", regex=False)
                         .str.extract(r"([\d\.]+)")[0])
        est_return = pd.to_numeric(raw, errors="coerce")
        rand_series = pd.Series(np.random.uniform(1.0, 8.0, len(df)), index=df.index)
        est_return = (est_return.fillna(rand_series) / 100.0).astype(float).round(4)
    else:
        # í€ë“œëŠ” ì¡°ê¸ˆ ë” ë„“ì€ ë²”ìœ„ë¡œ ì¤„ ìˆ˜ë„ ìˆìŒ(0.03~0.15)
        low, high = (0.01, 0.08) if group_name != "í€ë“œ" else (0.03, 0.15)
        est_return = pd.Series(np.round(np.random.uniform(low, high, len(df)), 4), index=df.index)

    # ë¦¬ìŠ¤í¬(ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ)
    if 'ìœ„í—˜ë“±ê¸‰' in df.columns:
        raw_risk = df['ìœ„í—˜ë“±ê¸‰'].astype(str)
        risk = raw_risk.apply(lambda x: 'ë†’ìŒ' if ('5' in x or '4' in x) else ('ì¤‘ê°„' if '3' in x else 'ë‚®ìŒ'))
    else:
        # í€ë“œëŠ” ë¶„ì‚° ì¡°ê¸ˆ ê³µê²©ì 
        if group_name == "í€ë“œ":
            risk = pd.Series(np.random.choice(['ë‚®ìŒ','ì¤‘ê°„','ë†’ìŒ'], len(df), p=[0.2,0.4,0.4]), index=df.index)
        else:
            risk = pd.Series(np.random.choice(['ë‚®ìŒ','ì¤‘ê°„','ë†’ìŒ'], len(df), p=[0.6,0.3,0.1]), index=df.index)

    # ê¶Œì¥ê¸°ê°„/íˆ¬ìì„±í–¥
    duration = pd.Series(np.random.choice([6, 12, 24, 36], len(df)), index=df.index)
    profile = pd.Series(np.random.choice(['ì•ˆì •í˜•','ìœ„í—˜ì¤‘ë¦½í˜•','ê³µê²©í˜•'], len(df)), index=df.index)

    out = pd.DataFrame({
        'êµ¬ë¶„': group_name if group_name else 'ê¸°íƒ€',
        'ìƒí’ˆëª…': names,
        'ìµœì†Œíˆ¬ìê¸ˆì•¡': min_invest.astype(int),
        'ì˜ˆìƒìˆ˜ìµë¥ ': est_return,
        'ë¦¬ìŠ¤í¬': risk,
        'ê¶Œì¥íˆ¬ìê¸°ê°„': duration,
        'íˆ¬ìì„±í–¥': profile
    })
    return out[out['ìƒí’ˆëª…'] != 'ë¬´ëª…ìƒí’ˆ'].drop_duplicates(subset=['ìƒí’ˆëª…']).reset_index(drop=True)

def rule_based_filter(df: pd.DataFrame, user: dict) -> pd.DataFrame:
    risk_pref_map = {
        'ì•ˆì •í˜•': ['ë‚®ìŒ','ì¤‘ê°„'],
        'ìœ„í—˜ì¤‘ë¦½í˜•': ['ì¤‘ê°„','ë‚®ìŒ','ë†’ìŒ'],
        'ê³µê²©í˜•': ['ë†’ìŒ','ì¤‘ê°„']
    }
    allowed_risks = risk_pref_map.get(user['íˆ¬ìì„±í–¥'], ['ë‚®ìŒ','ì¤‘ê°„','ë†’ìŒ'])

    filtered = df[
        (df['ìµœì†Œíˆ¬ìê¸ˆì•¡'] <= user['íˆ¬ìê¸ˆì•¡']) &
        (df['ê¶Œì¥íˆ¬ìê¸°ê°„'] <= user['íˆ¬ìê¸°ê°„']) &
        (df['ë¦¬ìŠ¤í¬'].isin(allowed_risks)) &
        (df['íˆ¬ìì„±í–¥'] == user['íˆ¬ìì„±í–¥'])
    ]
    if filtered.empty:
        filtered = df[
            (df['ìµœì†Œíˆ¬ìê¸ˆì•¡'] <= user['íˆ¬ìê¸ˆì•¡']) &
            (df['ê¶Œì¥íˆ¬ìê¸°ê°„'] <= user['íˆ¬ìê¸°ê°„']) &
            (df['ë¦¬ìŠ¤í¬'].isin(allowed_risks))
        ]
    return filtered.sort_values('ì˜ˆìƒìˆ˜ìµë¥ ', ascending=False).head(500).reset_index(drop=True)

def _get_feature_vector(df: pd.DataFrame) -> np.ndarray:
    return np.vstack([
        df['ìµœì†Œíˆ¬ìê¸ˆì•¡'].astype(float) / 1000.0,
        df['ì˜ˆìƒìˆ˜ìµë¥ '].astype(float) * 100.0,
        df['ê¶Œì¥íˆ¬ìê¸°ê°„'].astype(float) / 12.0
    ]).T.astype('float32')

def _get_user_vector(user: dict) -> np.ndarray:
    return np.array([
        user['íˆ¬ìê¸ˆì•¡'] / 1000.0,
        user['ëª©í‘œì›”ì´ì'],
        user['íˆ¬ìê¸°ê°„'] / 12.0
    ], dtype='float32').reshape(1, -1)

def _add_explain(df: pd.DataFrame, user: dict) -> pd.DataFrame:
    out = df.copy()
    out['ì›”ì˜ˆìƒìˆ˜ìµê¸ˆ(ë§Œì›)'] = (out['ì˜ˆìƒìˆ˜ìµë¥ '].astype(float) * user['íˆ¬ìê¸ˆì•¡'] / 12.0).round(1)
    out['íˆ¬ìê¸°ê°„(ê°œì›”)'] = out['ê¶Œì¥íˆ¬ìê¸°ê°„'].astype(int)
    out['ì˜ˆìƒìˆ˜ìµë¥ (ì—°)'] = (out['ì˜ˆìƒìˆ˜ìµë¥ '] * 100).round(2).astype(str) + '%'
    cols = ['êµ¬ë¶„','ìƒí’ˆëª…','ì›”ì˜ˆìƒìˆ˜ìµê¸ˆ(ë§Œì›)','ì˜ˆìƒìˆ˜ìµë¥ (ì—°)','ë¦¬ìŠ¤í¬','íˆ¬ìê¸°ê°„(ê°œì›”)']
    if 'êµ¬ë¶„' not in out.columns:
        out['êµ¬ë¶„'] = 'ê¸°íƒ€'
    return out[cols]

def recommend_with_saved_index(index, meta_df: pd.DataFrame, user: dict, topk: int):
    filtered = rule_based_filter(meta_df, user)
    if filtered.empty:
        return pd.DataFrame({'ë©”ì‹œì§€': ['ì¡°ê±´ì— ë§ëŠ” ìƒí’ˆì´ ì—†ì–´ìš” ğŸ˜¢']})

    allowed_ids = set(filtered.index.tolist())
    q = _get_user_vector(user)
    k_search = min(max(topk * 20, 100), len(meta_df))
    D, I = index.search(q, k_search)
    picked_ids = [int(i) for i in I[0] if int(i) in allowed_ids]

    if not picked_ids:
        rec = filtered.head(topk).copy()
    else:
        rec = meta_df.iloc[picked_ids].copy().loc[picked_ids].head(topk)

    rec = rec.drop_duplicates(subset=['ìƒí’ˆëª…']).head(topk)
    return _add_explain(rec, user).reset_index(drop=True)

# ---- ì¦‰ì‹œ êµ¬ì¶•(í´ë°±): ì˜ˆÂ·ì ê¸ˆ 2 + í€ë“œ 1 ----
def recommend_products_fallback_split(deposit_raw: pd.DataFrame, fund_raw: pd.DataFrame, user: dict):
    dep = preprocess_products(deposit_raw, group_name="ì˜ˆÂ·ì ê¸ˆ")
    fun = preprocess_products(fund_raw,    group_name="í€ë“œ")

    dep_f = rule_based_filter(dep, user)
    fun_f = rule_based_filter(fun, user)

    if dep_f.empty and fun_f.empty:
        return pd.DataFrame({'ë©”ì‹œì§€': ['ì¡°ê±´ì— ë§ëŠ” ìƒí’ˆì´ ì—†ì–´ìš” ğŸ˜¢']})

    # ì˜ˆÂ·ì ê¸ˆ 2ê°œ
    if not dep_f.empty:
        Xd = _get_feature_vector(dep_f)
        idxd = faiss.IndexFlatL2(Xd.shape[1]); idxd.add(Xd)
        _, idd = idxd.search(_get_user_vector(user), min(2, len(dep_f)))
        rec_dep = dep_f.iloc[idd[0]].copy().head(2)
    else:
        rec_dep = pd.DataFrame(columns=dep_f.columns)  # ë¹ˆ DF

    # í€ë“œ 1ê°œ
    if not fun_f.empty:
        Xf = _get_feature_vector(fun_f)
        idxf = faiss.IndexFlatL2(Xf.shape[1]); idxf.add(Xf)
        _, idf = idxf.search(_get_user_vector(user), min(1, len(fun_f)))
        rec_fun = fun_f.iloc[idf[0]].copy().head(1)
    else:
        rec_fun = pd.DataFrame(columns=fun_f.columns)

    out = pd.concat([rec_dep, rec_fun], ignore_index=True)
    out = out.drop_duplicates(subset=['ìƒí’ˆëª…']).reset_index(drop=True)
    return _add_explain(out, user)

# =================================
# UI íë¦„ ê´€ë¦¬
# =================================
st.title("ğŸ’¬ ì‹œë‹ˆì–´ ê¸ˆìœµ ì„¤ë¬¸ & ì¶”ì²œ ì‹œìŠ¤í…œ")

ss = st.session_state
ss.setdefault("flow", "choose")      # choose â†’ predict â†’ survey â†’ recommend
ss.setdefault("pred_amount", None)
ss.setdefault("answers", {})

# ê³µí†µ ì„¤ë¬¸ ë¬¸í•­
QUESTIONS = [
    ("ë‚˜ì´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", "number", "age"),
    ("ì„±ë³„ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", "select", "gender", ["ë‚¨ì„±", "ì—¬ì„±"]),
    ("ê°€êµ¬ì› ìˆ˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", "number", "family_size"),
    ("í”¼ë¶€ì–‘ìê°€ ìˆë‚˜ìš”?", "select", "dependents", ["ì˜ˆ", "ì•„ë‹ˆì˜¤"]),
    ("í˜„ì¬ ë³´ìœ í•œ ê¸ˆìœµìì‚°(ë§Œì›)ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", "number", "assets"),
    ("ì›” ìˆ˜ë ¹í•˜ëŠ” ì—°ê¸ˆ ê¸ˆì•¡(ë§Œì›)ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", "number", "pension"),
    ("ì›” í‰ê·  ì§€ì¶œë¹„(ë§Œì›)ì€ ì–¼ë§ˆì¸ê°€ìš”?", "number", "living_cost"),
    ("ì›” í‰ê·  ì†Œë“ì€ ì–¼ë§ˆì¸ê°€ìš”?", "number", "income"),
    ("íˆ¬ì ì„±í–¥ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", "select", "risk",
        ["ì•ˆì •í˜•", "ì•ˆì •ì¶”êµ¬í˜•", "ìœ„í—˜ì¤‘ë¦½í˜•", "ì ê·¹íˆ¬ìí˜•", "ê³µê²©íˆ¬ìí˜•"]),
]

def render_survey():
    st.subheader("ğŸ“ ì„¤ë¬¸")
    answers = {}
    for q in QUESTIONS:
        title, kind, key = q[0], q[1], q[2]
        if kind == "number":
            answers[key] = st.number_input(title, min_value=0, step=1, key=f"q_{key}")
        elif kind == "select":
            answers[key] = st.selectbox(title, q[3], key=f"q_{key}")
    return answers

def map_survey_to_model_input(r):
    gender = 0 if r["gender"] == "ë‚¨ì„±" else 1
    dependents = 1 if r["dependents"] == "ì˜ˆ" else 0
    risk_map = {"ì•ˆì •í˜•": 0, "ì•ˆì •ì¶”êµ¬í˜•": 1, "ìœ„í—˜ì¤‘ë¦½í˜•": 2, "ì ê·¹íˆ¬ìí˜•": 3, "ê³µê²©íˆ¬ìí˜•": 4}
    risk = risk_map[r["risk"]]
    arr = np.array([[
        float(r["age"]), gender, float(r["family_size"]), dependents,
        float(r["assets"]), float(r["pension"]), float(r["living_cost"]),
        float(r["income"]), risk
    ]])
    return arr

# 1) ì—°ê¸ˆ ìˆ˜ë ¹ ì—¬ë¶€
if ss.flow == "choose":
    st.markdown("### 1ï¸âƒ£ í˜„ì¬ ì—°ê¸ˆì„ ë°›ê³  ê³„ì‹ ê°€ìš”?")
    choice = st.radio("ì—°ê¸ˆ ìˆ˜ë ¹ ì—¬ë¶€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.", ["ì„ íƒí•˜ì„¸ìš”", "ì˜ˆ(ìˆ˜ë ¹ ì¤‘)", "ì•„ë‹ˆì˜¤(ë¯¸ìˆ˜ë ¹)"], index=0)
    if choice == "ì˜ˆ(ìˆ˜ë ¹ ì¤‘)":
        ss.flow = "survey"
    elif choice == "ì•„ë‹ˆì˜¤(ë¯¸ìˆ˜ë ¹)":
        ss.flow = "predict"

# 2-1) ë¯¸ìˆ˜ë ¹ì â†’ ì—°ê¸ˆ ê³„ì‚°ê¸°
if ss.flow == "predict":
    st.subheader("ğŸ“ˆ ì—°ê¸ˆ ê³„ì‚°ê¸°")
    income = st.number_input("í‰ê·  ì›”ì†Œë“(ë§Œì›)", min_value=0, step=1, key="pred_income")
    years  = st.number_input("êµ­ë¯¼ì—°ê¸ˆ ê°€ì…ê¸°ê°„(ë…„)", min_value=0, max_value=50, step=1, key="pred_years")

    if st.button("ì—°ê¸ˆ ì˜ˆì¸¡í•˜ê¸°"):
        X = pd.DataFrame([{"í‰ê· ì›”ì†Œë“(ë§Œì›)": income, "ê°€ì…ê¸°ê°„(ë…„)": years}])
        amount = round(float(reg_model.predict(X)[0]), 1)
        ss.pred_amount = amount

        def classify_pension_type(a):
            if a >= 90: return "ì™„ì „ë…¸ë ¹ì—°ê¸ˆ"
            if a >= 60: return "ì¡°ê¸°ë…¸ë ¹ì—°ê¸ˆ"
            if a >= 30: return "ê°ì•¡ë…¸ë ¹ì—°ê¸ˆ"
            return "íŠ¹ë¡€ë…¸ë ¹ì—°ê¸ˆ"

        ptype = classify_pension_type(amount)
        explains = {
            "ì¡°ê¸°ë…¸ë ¹ì—°ê¸ˆ": "â€» ë§Œ 60ì„¸ë¶€í„° ìˆ˜ë ¹ ê°€ëŠ¥í•˜ë‚˜ ìµœëŒ€ 30% ê°ì•¡ë  ìˆ˜ ìˆì–´ìš”.",
            "ì™„ì „ë…¸ë ¹ì—°ê¸ˆ": "â€» ë§Œ 65ì„¸ë¶€í„° ê°ì•¡ ì—†ì´ ì •ì•¡ ìˆ˜ë ¹ì´ ê°€ëŠ¥í•´ìš”.",
            "ê°ì•¡ë…¸ë ¹ì—°ê¸ˆ": "â€» ì¼ì • ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ëª»í•  ê²½ìš° ê°ì•¡ë˜ì–´ ìˆ˜ë ¹ë©ë‹ˆë‹¤.",
            "íŠ¹ë¡€ë…¸ë ¹ì—°ê¸ˆ": "â€» ê°€ì…ê¸°ê°„ì´ ì§§ë”ë¼ë„ ì¼ì • ê¸°ì¤€ ì¶©ì¡± ì‹œ ìˆ˜ë ¹ ê°€ëŠ¥."
        }
        st.success(f"ğŸ’° ì˜ˆì¸¡ ì—°ê¸ˆ ìˆ˜ë ¹ì•¡: **{amount}ë§Œì›/ì›”**")
        st.markdown(f"ğŸ“‚ ì˜ˆì¸¡ ì—°ê¸ˆ ìœ í˜•: **{ptype}**")
        st.info(explains[ptype])

        ss.flow = "survey"

# 2) ìˆ˜ë ¹ì/ë¯¸ìˆ˜ë ¹ì ê³µí†µ â†’ ì„¤ë¬¸ â†’ ìœ í˜• ë¶„ë¥˜
if ss.flow == "survey":
    answers = render_survey()
    if st.button("ìœ í˜• ë¶„ë¥˜í•˜ê¸°"):
        arr = map_survey_to_model_input(answers)
        pred = survey_model.predict(arr)
        label = survey_encoder.inverse_transform(pred)[0]

        proba = survey_model.predict_proba(arr)
        proba_df = pd.DataFrame(proba, columns=survey_encoder.classes_)
        predicted_proba = float(proba_df[label].values[0])

        st.success(f"ğŸ§¾ ì˜ˆì¸¡ëœ ê¸ˆìœµ ìœ í˜•: **{label}** (í™•ë¥  {predicted_proba*100:.1f}%)")
        st.bar_chart(proba_df.T)

        ss.answers = answers
        ss.flow = "recommend"

# 3) ì¶”ì²œ: ì„¤ë¬¸ + íˆ¬ìì¡°ê±´ ì…ë ¥ â†’ ì¶”ì²œ
if ss.flow == "recommend":
    st.markdown("---")
    st.subheader("ğŸ§² ê¸ˆìœµìƒí’ˆ ì¶”ì²œ")

    invest_amount  = st.number_input("íˆ¬ìê¸ˆì•¡(ë§Œì›)", min_value=10, step=10, value=500)
    invest_period  = st.selectbox("íˆ¬ìê¸°ê°„(ê°œì›”)", [6, 12, 24, 36], index=1)
    risk_choice    = st.selectbox("ë¦¬ìŠ¤í¬ í—ˆìš©ë„", ["ì•ˆì •í˜•", "ìœ„í—˜ì¤‘ë¦½í˜•", "ê³µê²©í˜•"], index=1)
    target_monthly = st.number_input("ëª©í‘œ ì›”ì´ì(ë§Œì›)", min_value=1, step=1, value=10)

    if st.button("ì¶”ì²œ ë³´ê¸°"):
        user_pref = {
            'íˆ¬ìê¸ˆì•¡': invest_amount,
            'íˆ¬ìê¸°ê°„': invest_period,
            'íˆ¬ìì„±í–¥': risk_choice,
            'ëª©í‘œì›”ì´ì': target_monthly
        }

        dep_idx  = saved_assets.get("deposit_index")
        dep_meta = saved_assets.get("deposit_meta")
        fund_idx  = saved_assets.get("fund_index")
        fund_meta = saved_assets.get("fund_meta")
        use_saved = (dep_idx is not None and dep_meta is not None and
                     fund_idx is not None and fund_meta is not None)

        if use_saved:
            # âœ… ì €ì¥ëœ ì¸ë±ìŠ¤/ë©”íƒ€ë°ì´í„° ì‚¬ìš©: ì˜ˆÂ·ì ê¸ˆ 2 + í€ë“œ 1
            rec_dep  = recommend_with_saved_index(dep_idx,  dep_meta,  user_pref, topk=2)
            rec_fund = recommend_with_saved_index(fund_idx, fund_meta, user_pref, topk=1)

            if "ë©”ì‹œì§€" in rec_dep.columns and "ë©”ì‹œì§€" in rec_fund.columns:
                st.warning("ì¡°ê±´ì— ë§ëŠ” ìƒí’ˆì´ ì—†ì–´ìš” ğŸ˜¢")
            else:
                parts = []
                if "ë©”ì‹œì§€" not in rec_dep.columns:  parts.append(rec_dep)
                if "ë©”ì‹œì§€" not in rec_fund.columns: parts.append(rec_fund)
                final_df = pd.concat(parts, ignore_index=True)

                st.dataframe(final_df, use_container_width=True)
                csv_bytes = final_df.to_csv(index=False).encode('utf-8-sig')
                st.download_button("ì¶”ì²œ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", csv_bytes, "recommendations.csv", "text/csv")
        else:
            # âš ï¸ ì €ì¥ ìì‚°ì´ ì—†ìœ¼ë©´ CSV ë‘ ê°œë¡œ ì¦‰ì‹œ êµ¬ì¶•í•˜ì—¬ ì˜ˆÂ·ì ê¸ˆ 2 + í€ë“œ 1 ì¶”ì²œ
            try:
                deposit_raw = load_deposit_csv()
                fund_raw    = load_fund_csv()
            except FileNotFoundError as e:
                st.error(str(e))
            else:
                rec_df = recommend_products_fallback_split(deposit_raw, fund_raw, user_pref)
                if "ë©”ì‹œì§€" in rec_df.columns:
                    st.warning(rec_df.iloc[0, 0])
                else:
                    st.dataframe(rec_df, use_container_width=True)
                    csv_bytes = rec_df.to_csv(index=False).encode('utf-8-sig')
                    st.download_button("ì¶”ì²œ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", csv_bytes, "recommendations.csv", "text/csv")

    if st.button("ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        for k in ["flow", "pred_amount", "answers"]:
            if k in st.session_state:
                del st.session_state[k]
        st.rerun()
