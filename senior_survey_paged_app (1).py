# app.py
# === ì§„ë‹¨/ì•ˆì „ ë¡œë” ìœ í‹¸ (app.py ìƒë‹¨ import ì•„ë˜) ===
import platform, sys

def safe_joblib_load(path, name):
    try:
        obj = joblib.load(path)
        st.sidebar.success(f"âœ… {name} ë¡œë“œ: {os.path.basename(path)}")
        return obj
    except Exception as e:
        st.sidebar.error(f"âŒ {name} ë¡œë“œ ì‹¤íŒ¨: {os.path.basename(path)}")
        st.sidebar.exception(e)
        return None

def safe_faiss_read(path, name):
    try:
        import faiss  # ì„¤ì¹˜ ì‹¤íŒ¨ì‹œ ImportError
        idx = faiss.read_index(path)
        st.sidebar.success(f"âœ… {name} ì¸ë±ìŠ¤ ë¡œë“œ: {os.path.basename(path)}")
        return idx
    except Exception as e:
        st.sidebar.error(f"âŒ {name} ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {os.path.basename(path)}")
        st.sidebar.exception(e)
        return None

def file_exists(path):
    ok = os.path.exists(path)
    st.sidebar.write(("ğŸŸ¢" if ok else "ğŸ”´"), path)
    return ok

def show_env():
    st.sidebar.header("ğŸ§ª í™˜ê²½/ë²„ì „")
    st.sidebar.write("Python:", sys.version.split()[0])
    st.sidebar.write("Platform:", platform.platform())
    try:
        import numpy as np; st.sidebar.write("numpy:", np.__version__)
    except: pass
    try:
        import pandas as pd; st.sidebar.write("pandas:", pd.__version__)
    except: pass
    try:
        import faiss; st.sidebar.write("faiss:", faiss.__version__)
    except Exception as e:
        st.sidebar.warning("faiss ë¶ˆê°€"); st.sidebar.write(str(e))
    try:
        import torch; st.sidebar.write("torch:", torch.__version__)
    except: pass


import os
import re
import numpy as np
import pandas as pd
import streamlit as st
import joblib
import faiss

# =================================
# ê¸°ë³¸ ì„¤ì •
# =================================
st.set_page_config(page_title="ì‹œë‹ˆì–´ ê¸ˆìœµ ì„¤ë¬¸ & ì¶”ì²œ", page_icon="ğŸ’¸", layout="centered")

# ì‹¤í–‰ íŒŒì¼ ê¸°ì¤€ ê²½ë¡œ (Streamlit/ë¡œì»¬ ëª¨ë‘ ì•ˆì „)
BASE_DIR = os.path.dirname(os.path.abspath(__file__)) if "__file__" in globals() else os.getcwd()
MODELS_DIR = BASE_DIR          # ëª¨ë¸/ì¸ë±ìŠ¤/CSV ëª¨ë‘ ê°™ì€ í´ë”ë¼ê³  ê°€ì •
PRODUCTS_CSV = "ê¸ˆìœµìƒí’ˆ_3ê°œ_í†µí•©ë³¸.csv"  # ì¦‰ì‹œ êµ¬ì¶•(í´ë°±)ìš© ì›ì‹œ ìƒí’ˆ CSV

# =================================
# ëª¨ë¸/ë°ì´í„° ë¡œë”© (ìºì‹œ)
# =================================
@st.cache_resource
def load_models():
    survey_model   = joblib.load(os.path.join(MODELS_DIR, "tabnet_model.pkl"))
    survey_encoder = joblib.load(os.path.join(MODELS_DIR, "label_encoder.pkl"))
    reg_model      = joblib.load(os.path.join(MODELS_DIR, "reg_model.pkl"))
    type_model     = joblib.load(os.path.join(MODELS_DIR, "type_model.pkl"))
    return survey_model, survey_encoder, reg_model, type_model

@st.cache_resource
def load_saved_reco_assets():
    """
    ì €ì¥ëœ ì¶”ì²œ ìì‚°(FAISS ì¸ë±ìŠ¤ + ë©”íƒ€ë°ì´í„°) ë¡œë”©
    - ì˜ˆÂ·ì ê¸ˆ: deposit_index.faiss / deposit_metadata.parquet
    - í€ë“œ  : fund_index.faiss    / fund_metadata.parquet
    """
    assets = {
        "deposit_index": None, "deposit_meta": None,
        "fund_index": None,    "fund_meta": None
    }
    dep_idx_path  = os.path.join(MODELS_DIR, "deposit_index.faiss")
    dep_meta_path = os.path.join(MODELS_DIR, "deposit_metadata.parquet")
    fund_idx_path  = os.path.join(MODELS_DIR, "fund_index.faiss")
    fund_meta_path = os.path.join(MODELS_DIR, "fund_metadata.parquet")

    if os.path.exists(dep_idx_path) and os.path.exists(dep_meta_path):
        assets["deposit_index"] = faiss.read_index(dep_idx_path)
        assets["deposit_meta"]  = pd.read_parquet(dep_meta_path)
    if os.path.exists(fund_idx_path) and os.path.exists(fund_meta_path):
        assets["fund_index"] = faiss.read_index(fund_idx_path)
        assets["fund_meta"]  = pd.read_parquet(fund_meta_path)
    return assets

@st.cache_data
def load_products_fixed():
    """ì¦‰ì‹œ êµ¬ì¶•(í´ë°±)ìš© í†µí•© CSV ë¡œë”©"""
    path = os.path.join(BASE_DIR, PRODUCTS_CSV)
    if not os.path.exists(path):
        raise FileNotFoundError(f"ìƒí’ˆ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}")
    try:
        df = pd.read_csv(path, encoding="utf-8-sig")
    except UnicodeDecodeError:
        df = pd.read_csv(path, encoding="cp949")
    return df

survey_model, survey_encoder, reg_model, type_model = load_models()
saved_assets = load_saved_reco_assets()
raw_products = load_products_fixed()

# =================================
# ì „ì²˜ë¦¬ ë° ì¶”ì²œ ìœ í‹¸
# =================================
def preprocess_products(df: pd.DataFrame) -> pd.DataFrame:
    """ì¦‰ì‹œ êµ¬ì¶•(í´ë°±)ìš© ì „ì²˜ë¦¬"""
    np.random.seed(42)
    df = df.copy()
    df.columns = df.columns.str.strip()

    # ìƒí’ˆëª…
    if 'ìƒí’ˆëª…' in df.columns:
        names = df['ìƒí’ˆëª…'].fillna('ë¬´ëª…ìƒí’ˆ').astype(str)
    elif 'í€ë“œëª…' in df.columns:
        names = df['í€ë“œëª…'].fillna('ë¬´ëª…ìƒí’ˆ').astype(str)
    elif 'ì¶œì²˜íŒŒì¼ëª…' in df.columns:
        names = df['ì¶œì²˜íŒŒì¼ëª…'].apply(lambda x: str(x).split('.')[0] if pd.notnull(x) else 'ë¬´ëª…ìƒí’ˆ')
    else:
        names = [f"ë¬´ëª…ìƒí’ˆ_{i}" for i in range(len(df))]

    # ìµœì†Œ íˆ¬ìê¸ˆì•¡
    if 'ìµœê³ í•œë„' in df.columns:
        min_invest = pd.to_numeric(df['ìµœê³ í•œë„'], errors='coerce').fillna(0)
        zero_mask = (min_invest == 0)
        if zero_mask.any():
            min_invest.loc[zero_mask] = np.random.randint(100, 1000, zero_mask.sum())
    else:
        min_invest = pd.Series(np.random.randint(100, 1000, len(df)), index=df.index)

    # ìˆ˜ìµë¥ (%) â†’ ì†Œìˆ˜
    cand_cols = [c for c in df.columns if any(k in c for k in ["ê¸°ë³¸ê¸ˆë¦¬", "ì´ììœ¨", "ì„¸ì „", "%"])]
    rate_col = cand_cols[0] if cand_cols else None
    if rate_col:
        raw = (df[rate_col].astype(str)
                         .str.replace(",", "", regex=False)
                         .str.extract(r"([\d\.]+)")[0])
        est_return = pd.to_numeric(raw, errors="coerce")
        rand_series = pd.Series(np.random.uniform(1.0, 8.0, len(df)), index=df.index)
        est_return = (est_return.fillna(rand_series) / 100.0).astype(float).round(4)
    else:
        est_return = pd.Series(np.round(np.random.uniform(0.01, 0.08, len(df)), 4), index=df.index)

    # ë¦¬ìŠ¤í¬(ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ)
    if 'ìœ„í—˜ë“±ê¸‰' in df.columns:
        raw_risk = df['ìœ„í—˜ë“±ê¸‰'].astype(str)
        risk = raw_risk.apply(lambda x: 'ë†’ìŒ' if ('5' in x or '4' in x) else ('ì¤‘ê°„' if '3' in x else 'ë‚®ìŒ'))
    else:
        risk = pd.Series(np.random.choice(['ë‚®ìŒ','ì¤‘ê°„','ë†’ìŒ'], len(df)), index=df.index)

    # ê¶Œì¥ê¸°ê°„/íˆ¬ìì„±í–¥
    duration = pd.Series(np.random.choice([6, 12, 24, 36], len(df)), index=df.index)
    profile = pd.Series(np.random.choice(['ì•ˆì •í˜•','ìœ„í—˜ì¤‘ë¦½í˜•','ê³µê²©í˜•'], len(df)), index=df.index)

    out = pd.DataFrame({
        'ìƒí’ˆëª…': names,
        'ìµœì†Œíˆ¬ìê¸ˆì•¡': min_invest.astype(int),
        'ì˜ˆìƒìˆ˜ìµë¥ ': est_return,
        'ë¦¬ìŠ¤í¬': risk,
        'ê¶Œì¥íˆ¬ìê¸°ê°„': duration,
        'íˆ¬ìì„±í–¥': profile
    })
    return out[out['ìƒí’ˆëª…'] != 'ë¬´ëª…ìƒí’ˆ'].drop_duplicates(subset=['ìƒí’ˆëª…']).reset_index(drop=True)

def rule_based_filter(df: pd.DataFrame, user: dict) -> pd.DataFrame:
    # ì‚¬ìš©ì ë¦¬ìŠ¤í¬ í—ˆìš©ë„ ê¸°ì¤€ í—ˆìš© ë¦¬ìŠ¤í¬ ì •ì˜
    risk_pref_map = {
        'ì•ˆì •í˜•': ['ë‚®ìŒ','ì¤‘ê°„'],
        'ìœ„í—˜ì¤‘ë¦½í˜•': ['ì¤‘ê°„','ë‚®ìŒ','ë†’ìŒ'],
        'ê³µê²©í˜•': ['ë†’ìŒ','ì¤‘ê°„']
    }
    allowed_risks = risk_pref_map.get(user['íˆ¬ìì„±í–¥'], ['ë‚®ìŒ','ì¤‘ê°„','ë†’ìŒ'])

    filtered = df[
        (df['ìµœì†Œíˆ¬ìê¸ˆì•¡'] <= user['íˆ¬ìê¸ˆì•¡']) &
        (df['ê¶Œì¥íˆ¬ìê¸°ê°„'] <= user['íˆ¬ìê¸°ê°„']) &
        (df['ë¦¬ìŠ¤í¬'].isin(allowed_risks)) &
        (df['íˆ¬ìì„±í–¥'] == user['íˆ¬ìì„±í–¥'])
    ]
    if filtered.empty:
        # ë„ˆë¬´ íƒ€ì´íŠ¸í•˜ë©´ ì„±í–¥ë§Œ ì™„í™”
        filtered = df[
            (df['ìµœì†Œíˆ¬ìê¸ˆì•¡'] <= user['íˆ¬ìê¸ˆì•¡']) &
            (df['ê¶Œì¥íˆ¬ìê¸°ê°„'] <= user['íˆ¬ìê¸°ê°„']) &
            (df['ë¦¬ìŠ¤í¬'].isin(allowed_risks))
        ]
    return filtered.sort_values('ì˜ˆìƒìˆ˜ìµë¥ ', ascending=False).head(500).reset_index(drop=True)

def _get_feature_vector(df: pd.DataFrame) -> np.ndarray:
    return np.vstack([
        df['ìµœì†Œíˆ¬ìê¸ˆì•¡'].astype(float) / 1000.0,
        df['ì˜ˆìƒìˆ˜ìµë¥ '].astype(float) * 100.0,
        df['ê¶Œì¥íˆ¬ìê¸°ê°„'].astype(float) / 12.0
    ]).T.astype('float32')

def _get_user_vector(user: dict) -> np.ndarray:
    return np.array([
        user['íˆ¬ìê¸ˆì•¡'] / 1000.0,
        user['ëª©í‘œì›”ì´ì'],
        user['íˆ¬ìê¸°ê°„'] / 12.0
    ], dtype='float32').reshape(1, -1)

def _add_explain(df: pd.DataFrame, user: dict) -> pd.DataFrame:
    out = df.copy()
    out['ì›”ì˜ˆìƒìˆ˜ìµê¸ˆ(ë§Œì›)'] = (out['ì˜ˆìƒìˆ˜ìµë¥ '].astype(float) * user['íˆ¬ìê¸ˆì•¡'] / 12.0).round(1)
    out['íˆ¬ìê¸°ê°„(ê°œì›”)'] = out['ê¶Œì¥íˆ¬ìê¸°ê°„'].astype(int)
    out['ì˜ˆìƒìˆ˜ìµë¥ (ì—°)'] = (out['ì˜ˆìƒìˆ˜ìµë¥ '] * 100).round(2).astype(str) + '%'
    return out[['ìƒí’ˆëª…','ì›”ì˜ˆìƒìˆ˜ìµê¸ˆ(ë§Œì›)','ì˜ˆìƒìˆ˜ìµë¥ (ì—°)','ë¦¬ìŠ¤í¬','íˆ¬ìê¸°ê°„(ê°œì›”)']]

def recommend_with_saved_index(index, meta_df: pd.DataFrame, user: dict, topk: int):
    """
    ì €ì¥ëœ ì¸ë±ìŠ¤/ë©”íƒ€ë°ì´í„°ë¥¼ ì´ìš©í•´ ì¶”ì²œ.
    ë©”íƒ€ë°ì´í„°ì˜ 'í–‰ ì¸ë±ìŠ¤'ê°€ add() ìˆœì„œì™€ ë™ì¼í•˜ë‹¤ëŠ” ê°€ì •.
    """
    filtered = rule_based_filter(meta_df, user)
    if filtered.empty:
        return pd.DataFrame({'ë©”ì‹œì§€': ['ì¡°ê±´ì— ë§ëŠ” ìƒí’ˆì´ ì—†ì–´ìš” ğŸ˜¢']})

    allowed_ids = set(filtered.index.tolist())
    q = _get_user_vector(user)
    k_search = min(max(topk * 20, 100), len(meta_df))  # ë„‰ë„‰íˆ ê²€ìƒ‰
    D, I = index.search(q, k_search)
    picked_ids = [int(i) for i in I[0] if int(i) in allowed_ids]

    if not picked_ids:
        rec = filtered.head(topk).copy()
    else:
        rec = meta_df.iloc[picked_ids].copy().loc[picked_ids].head(topk)

    rec = rec.drop_duplicates(subset=['ìƒí’ˆëª…']).head(topk)
    return _add_explain(rec, user).reset_index(drop=True)

# ---- ì¦‰ì‹œ êµ¬ì¶•(í´ë°±)ìš© ì¶”ì²œ (Top-3 í†µí•©) ----
def recommend_products_fallback(raw_df: pd.DataFrame, user: dict, topk: int = 3):
    processed = preprocess_products(raw_df)
    filtered = rule_based_filter(processed, user)
    if filtered.empty:
        return pd.DataFrame({'ë©”ì‹œì§€': ['ì¡°ê±´ì— ë§ëŠ” ìƒí’ˆì´ ì—†ì–´ìš” ğŸ˜¢']}), None
    filtered = filtered.drop_duplicates(subset=['ìƒí’ˆëª…'])
    X = _get_feature_vector(filtered)
    index = faiss.IndexFlatL2(X.shape[1]); index.add(X)
    _, idx = index.search(_get_user_vector(user), min(topk, len(filtered)))
    rec = filtered.iloc[idx[0]].drop_duplicates(subset=['ìƒí’ˆëª…']).head(topk).reset_index(drop=True)
    return _add_explain(rec, user), index

# =================================
# UI íë¦„ ê´€ë¦¬
# =================================
st.title("ğŸ’¬ ì‹œë‹ˆì–´ ê¸ˆìœµ ì„¤ë¬¸ & ì¶”ì²œ ì‹œìŠ¤í…œ")

ss = st.session_state
ss.setdefault("flow", "choose")      # choose â†’ predict â†’ survey â†’ recommend
ss.setdefault("pred_amount", None)   # ë¯¸ìˆ˜ë ¹ì ì˜ˆì¸¡ ì—°ê¸ˆì•¡
ss.setdefault("answers", {})         # ì„¤ë¬¸ ì‘ë‹µ

# ê³µí†µ ì„¤ë¬¸ ë¬¸í•­
QUESTIONS = [
    ("ë‚˜ì´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", "number", "age"),
    ("ì„±ë³„ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", "select", "gender", ["ë‚¨ì„±", "ì—¬ì„±"]),
    ("ê°€êµ¬ì› ìˆ˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", "number", "family_size"),
    ("í”¼ë¶€ì–‘ìê°€ ìˆë‚˜ìš”?", "select", "dependents", ["ì˜ˆ", "ì•„ë‹ˆì˜¤"]),
    ("í˜„ì¬ ë³´ìœ í•œ ê¸ˆìœµìì‚°(ë§Œì›)ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", "number", "assets"),
    ("ì›” ìˆ˜ë ¹í•˜ëŠ” ì—°ê¸ˆ ê¸ˆì•¡(ë§Œì›)ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", "number", "pension"),
    ("ì›” í‰ê·  ì§€ì¶œë¹„(ë§Œì›)ì€ ì–¼ë§ˆì¸ê°€ìš”?", "number", "living_cost"),
    ("ì›” í‰ê·  ì†Œë“ì€ ì–¼ë§ˆì¸ê°€ìš”?", "number", "income"),
    ("íˆ¬ì ì„±í–¥ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", "select", "risk",
        ["ì•ˆì •í˜•", "ì•ˆì •ì¶”êµ¬í˜•", "ìœ„í—˜ì¤‘ë¦½í˜•", "ì ê·¹íˆ¬ìí˜•", "ê³µê²©íˆ¬ìí˜•"]),
]

def render_survey():
    st.subheader("ğŸ“ ì„¤ë¬¸")
    answers = {}
    for q in QUESTIONS:
        title, kind, key = q[0], q[1], q[2]
        if kind == "number":
            answers[key] = st.number_input(title, min_value=0, step=1, key=f"q_{key}")
        elif kind == "select":
            answers[key] = st.selectbox(title, q[3], key=f"q_{key}")
    return answers

def map_survey_to_model_input(r):
    gender = 0 if r["gender"] == "ë‚¨ì„±" else 1
    dependents = 1 if r["dependents"] == "ì˜ˆ" else 0
    risk_map = {"ì•ˆì •í˜•": 0, "ì•ˆì •ì¶”êµ¬í˜•": 1, "ìœ„í—˜ì¤‘ë¦½í˜•": 2, "ì ê·¹íˆ¬ìí˜•": 3, "ê³µê²©íˆ¬ìí˜•": 4}
    risk = risk_map[r["risk"]]
    arr = np.array([[
        float(r["age"]), gender, float(r["family_size"]), dependents,
        float(r["assets"]), float(r["pension"]), float(r["living_cost"]),
        float(r["income"]), risk
    ]])
    return arr

# 1) ì—°ê¸ˆ ìˆ˜ë ¹ ì—¬ë¶€
if ss.flow == "choose":
    st.markdown("### 1ï¸âƒ£ í˜„ì¬ ì—°ê¸ˆì„ ë°›ê³  ê³„ì‹ ê°€ìš”?")
    choice = st.radio("ì—°ê¸ˆ ìˆ˜ë ¹ ì—¬ë¶€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.", ["ì„ íƒí•˜ì„¸ìš”", "ì˜ˆ(ìˆ˜ë ¹ ì¤‘)", "ì•„ë‹ˆì˜¤(ë¯¸ìˆ˜ë ¹)"], index=0)
    if choice == "ì˜ˆ(ìˆ˜ë ¹ ì¤‘)":
        ss.flow = "survey"
    elif choice == "ì•„ë‹ˆì˜¤(ë¯¸ìˆ˜ë ¹)":
        ss.flow = "predict"

# 2-1) ë¯¸ìˆ˜ë ¹ì â†’ ì—°ê¸ˆ ê³„ì‚°ê¸°
if ss.flow == "predict":
    st.subheader("ğŸ“ˆ ì—°ê¸ˆ ê³„ì‚°ê¸°")
    income = st.number_input("í‰ê·  ì›”ì†Œë“(ë§Œì›)", min_value=0, step=1, key="pred_income")
    years  = st.number_input("êµ­ë¯¼ì—°ê¸ˆ ê°€ì…ê¸°ê°„(ë…„)", min_value=0, max_value=50, step=1, key="pred_years")

    if st.button("ì—°ê¸ˆ ì˜ˆì¸¡í•˜ê¸°"):
        X = pd.DataFrame([{"í‰ê· ì›”ì†Œë“(ë§Œì›)": income, "ê°€ì…ê¸°ê°„(ë…„)": years}])
        amount = round(float(reg_model.predict(X)[0]), 1)
        ss.pred_amount = amount

        def classify_pension_type(a):
            if a >= 90: return "ì™„ì „ë…¸ë ¹ì—°ê¸ˆ"
            if a >= 60: return "ì¡°ê¸°ë…¸ë ¹ì—°ê¸ˆ"
            if a >= 30: return "ê°ì•¡ë…¸ë ¹ì—°ê¸ˆ"
            return "íŠ¹ë¡€ë…¸ë ¹ì—°ê¸ˆ"

        ptype = classify_pension_type(amount)
        explains = {
            "ì¡°ê¸°ë…¸ë ¹ì—°ê¸ˆ": "â€» ë§Œ 60ì„¸ë¶€í„° ìˆ˜ë ¹ ê°€ëŠ¥í•˜ë‚˜ ìµœëŒ€ 30% ê°ì•¡ë  ìˆ˜ ìˆì–´ìš”.",
            "ì™„ì „ë…¸ë ¹ì—°ê¸ˆ": "â€» ë§Œ 65ì„¸ë¶€í„° ê°ì•¡ ì—†ì´ ì •ì•¡ ìˆ˜ë ¹ì´ ê°€ëŠ¥í•´ìš”.",
            "ê°ì•¡ë…¸ë ¹ì—°ê¸ˆ": "â€» ì¼ì • ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ëª»í•  ê²½ìš° ê°ì•¡ë˜ì–´ ìˆ˜ë ¹ë©ë‹ˆë‹¤.",
            "íŠ¹ë¡€ë…¸ë ¹ì—°ê¸ˆ": "â€» ê°€ì…ê¸°ê°„ì´ ì§§ë”ë¼ë„ ì¼ì • ê¸°ì¤€ ì¶©ì¡± ì‹œ ìˆ˜ë ¹ ê°€ëŠ¥."
        }
        st.success(f"ğŸ’° ì˜ˆì¸¡ ì—°ê¸ˆ ìˆ˜ë ¹ì•¡: **{amount}ë§Œì›/ì›”**")
        st.markdown(f"ğŸ“‚ ì˜ˆì¸¡ ì—°ê¸ˆ ìœ í˜•: **{ptype}**")
        st.info(explains[ptype])

        ss.flow = "survey"

# 2) ìˆ˜ë ¹ì/ë¯¸ìˆ˜ë ¹ì ê³µí†µ â†’ ì„¤ë¬¸ â†’ ìœ í˜• ë¶„ë¥˜
if ss.flow == "survey":
    answers = render_survey()
    if st.button("ìœ í˜• ë¶„ë¥˜í•˜ê¸°"):
        arr = map_survey_to_model_input(answers)
        pred = survey_model.predict(arr)
        label = survey_encoder.inverse_transform(pred)[0]

        proba = survey_model.predict_proba(arr)
        proba_df = pd.DataFrame(proba, columns=survey_encoder.classes_)
        predicted_proba = float(proba_df[label].values[0])

        st.success(f"ğŸ§¾ ì˜ˆì¸¡ëœ ê¸ˆìœµ ìœ í˜•: **{label}** (í™•ë¥  {predicted_proba*100:.1f}%)")
        st.bar_chart(proba_df.T)

        ss.answers = answers
        ss.flow = "recommend"

# 3) ì¶”ì²œ: ì„¤ë¬¸ + íˆ¬ìì¡°ê±´ ì…ë ¥ â†’ ì¶”ì²œ
if ss.flow == "recommend":
    st.markdown("---")
    st.subheader("ğŸ§² ê¸ˆìœµìƒí’ˆ ì¶”ì²œ")

    invest_amount  = st.number_input("íˆ¬ìê¸ˆì•¡(ë§Œì›)", min_value=10, step=10, value=500)
    invest_period  = st.selectbox("íˆ¬ìê¸°ê°„(ê°œì›”)", [6, 12, 24, 36], index=1)
    risk_choice    = st.selectbox("ë¦¬ìŠ¤í¬ í—ˆìš©ë„", ["ì•ˆì •í˜•", "ìœ„í—˜ì¤‘ë¦½í˜•", "ê³µê²©í˜•"], index=1)
    target_monthly = st.number_input("ëª©í‘œ ì›”ì´ì(ë§Œì›)", min_value=1, step=1, value=10)

    if st.button("ì¶”ì²œ ë³´ê¸°"):
        user_pref = {
            'íˆ¬ìê¸ˆì•¡': invest_amount,
            'íˆ¬ìê¸°ê°„': invest_period,
            'íˆ¬ìì„±í–¥': risk_choice,
            'ëª©í‘œì›”ì´ì': target_monthly
        }

        # ì €ì¥ ìì‚° ë¡œë”© ê²°ê³¼
        dep_idx  = saved_assets.get("deposit_index")
        dep_meta = saved_assets.get("deposit_meta")
        fund_idx  = saved_assets.get("fund_index")
        fund_meta = saved_assets.get("fund_meta")
        use_saved = (dep_idx is not None and dep_meta is not None and
                     fund_idx is not None and fund_meta is not None)

        if use_saved:
            # âœ… ì €ì¥ëœ ì¸ë±ìŠ¤/ë©”íƒ€ë°ì´í„° ì‚¬ìš©: ì˜ˆÂ·ì ê¸ˆ 2 + í€ë“œ 1
            rec_dep  = recommend_with_saved_index(dep_idx,  dep_meta,  user_pref, topk=2)
            rec_fund = recommend_with_saved_index(fund_idx, fund_meta, user_pref, topk=1)

            if "ë©”ì‹œì§€" in rec_dep.columns and "ë©”ì‹œì§€" in rec_fund.columns:
                st.warning("ì¡°ê±´ì— ë§ëŠ” ìƒí’ˆì´ ì—†ì–´ìš” ğŸ˜¢")
            else:
                parts = []
                if "ë©”ì‹œì§€" not in rec_dep.columns:  parts.append(rec_dep.assign(êµ¬ë¶„="ì˜ˆÂ·ì ê¸ˆ"))
                if "ë©”ì‹œì§€" not in rec_fund.columns: parts.append(rec_fund.assign(êµ¬ë¶„="í€ë“œ"))
                final_df = pd.concat(parts, ignore_index=True)

                st.dataframe(final_df[['êµ¬ë¶„','ìƒí’ˆëª…','ì›”ì˜ˆìƒìˆ˜ìµê¸ˆ(ë§Œì›)','ì˜ˆìƒìˆ˜ìµë¥ (ì—°)','ë¦¬ìŠ¤í¬','íˆ¬ìê¸°ê°„(ê°œì›”)']],
                             use_container_width=True)
                csv_bytes = final_df.to_csv(index=False).encode('utf-8-sig')
                st.download_button("ì¶”ì²œ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", csv_bytes, "recommendations.csv", "text/csv")
        else:
            # âš ï¸ ì €ì¥ ìì‚°ì´ ì—†ì„ ë•Œ: ì¦‰ì‹œ êµ¬ì¶• ë°©ì‹ìœ¼ë¡œ Top-3 í†µí•© ì¶”ì²œ
            st.info("ì €ì¥ëœ ì¶”ì²œ ì¸ë±ìŠ¤ë¥¼ ì°¾ì§€ ëª»í•´, ì¦‰ì‹œ êµ¬ì¶• ë°©ì‹ìœ¼ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.")
            rec_df, _ = recommend_products_fallback(raw_products, user_pref, topk=3)
            if "ë©”ì‹œì§€" in rec_df.columns:
                st.warning(rec_df.iloc[0, 0])
            else:
                st.dataframe(rec_df, use_container_width=True)
                csv_bytes = rec_df.to_csv(index=False).encode('utf-8-sig')
                st.download_button("ì¶”ì²œ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", csv_bytes, "recommendations.csv", "text/csv")

    if st.button("ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        for k in ["flow", "pred_amount", "answers"]:
            if k in st.session_state:
                del st.session_state[k]
        st.rerun()
